########################################################################################
### ********************************** NOTES *************************************** ###
### Please follow the following pattern for all parameters: '${paramter} = ${value}' ###
### Please ensure that there are spaces preceeding and following the '=' sign.       ###
########################################################################################
# Output folder to save all information related to the model, i.e., the checkpoints, logs, csv
model_dir = /path/to/output/model/directory
# Structured input folder containing the training data containing the images after standarizing the intensity
train_dir = /path/to/traning/input/folder
# Structured input folder containing the validation data containing the images after standarizing the intensity
validation_dir = /path/to/validation/input/folder
# Mode: ma (modality-agnostic), single (only 1 modality is being used), multi (multiple modalities used)
mode = ma
# Whether using a csv file as input or not. If False, please provide the test_dir. [True or False]
csv_provided = False
# Input csv file when csv_provided=True. If csv_provided=False, please give a period.
train_csv = .
validation_csv = .
# Number of modalities. This should be 1 for modality-agnostic model.
num_modalities = 1
# Type of channels being used:
modalities = ['t1', 't2', 't1ce', 'flair']
# Set the type of encoder. Options: resunet, fcn, unet
model = resunet
# Set the number of classes. For brain masks, this should be 2 (brain and background).
num_classes = 2
# Set the minimum number of epochs
min_epochs = 10
# Set the maximum number of epochs
max_epochs = 100
# Set the Batch size
batch_size = 1
# Set the optimizer. Options: sgd, adam, adagrad, rms
optimizer = sgd
# Set the intial learning 
learning_rate = 0.01
# Set the learning rate milestones, each should be less than max_epochs
lr_milestones = [20, 40, 60, 80]
# Decay milestones, each should be less than max_epochs
decay_milestones = [40, 80]
# Early Stopping patience: the number of epochs to train till validation results does not improve; used as stopping criteria 
early_stop_patience = 10
# Set the depth of the Encoder
layers = 5
# Set the save best factor, this will determine how many best models do you wanna save (usually top 5)
save_best = 5
# Set the base filter of the unet
base_filters = 16
# Set the log interval
log_interval = 100
