###############################################################################################
### *************************************** NOTE ****************************************** ###
### Please Dont change anything on the left side of the equal sign and always keep only a   ###
### single space on the right side of the equal sign. Otherwise it will just break things   ###
### and you will post issues on github and I will have to explain this again.               ###
###############################################################################################
# Where do you want to save all information related to the model, i.e., the checkpoints, logs the stuff generated during testing like csvs and stuff
model_dir = /home/data/Results/BET/outputModel
# the location to keep the training data, i.e., the data **after** preprocessing
train_dir = /home/data/BET/preprocessed_train
# The validation Directory
validation_dir = /home/data/BET/preprocessed_validation
# Mode: one4all, single, multi
mode = one4all
# Are you providing test csv or should we create one for you? [True or False]
csv_provided = False
# Training csv path and validation csv path?
train_csv = .
validation_csv = .
# How many modalities are we expecting? Ofcourse 4! dont change this number unless you're smart
num_modalities = 1
# Type of channels you are gonna enter : NOTE : Remember that they should match with number of input  channels
modalities = ['t1', 't2', 't1ce', 'flair']
# Set the type of encoder you need to try out. Options: resunet, fcn, unet
model = resunet
# Number of classes? Maybe right now for skull stripping
num_classes = 2
# Set the minimum number of epochs
min_epochs = 10
# Set the maximum number of epochs
max_epochs = 100
# Set the Batch size right here
batch_size = 1
# Set up the optimizer. Options: sgd, adam, adagrad, rms
optimizer = sgd
# Set the intial learning 
learning_rate = 0.01
# Set the learning rate milestones, each should be less than max_epochs
lr_milestones = [20, 40, 60, 80]
# Decay milestones, each should be less than max_epochs
decay_milestones = [40, 80]
# EARLY Stopping patience, showing the number of epochs to train till validation results does not improve; used as stoppind criteria 
early_stop_patience = 10
# Learning rate drop patience
lr_decay_patience = 5
# Set the depth of the Encoder
layers = 5
# Set the save best factor, this will determine how many best models do you wanna save (usually top 5)
save_best = 5
# Set the base filter of the unet
base_filters = 16
# Set the log interval
log_interval = 100
