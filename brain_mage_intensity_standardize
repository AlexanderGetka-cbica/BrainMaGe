#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun May 24 13:49:24 2020

@author: siddhesh
"""


import numpy as np
import os
import glob
import nibabel as nib
import argparse
from skimage.transform import resize
from multiprocessing import Pool, cpu_count
import pkg_resources

def preprocess_image(nib_image, is_mask=False, target_shape=(128, 128, 128)):
    shape = nib_image.header.get_data_shape()
    image = nib_image.get_fdata()
    # Set interpolation to cubic if not mask else nearest
    order = 3 if not is_mask else 0
    if not is_mask:
        image = resize(new_image, target_shape, order=order,
                       mode='edge', cval=0, anti_aliasing=False)
        image -= image.mean()
        image /= image.std()
        image = image.astype(np.float32)
    else:
        image = resize(new_image, target_shape, order=order,
                       mode='edge', cval=0, anti_aliasing=False)
        image = (image>0).astype(np.int8)
    return image

def normalize(folder, dest_folder, patient_name, test=False):
    """[Function used to pre-process files]
    [This function is used for the skull stripping preprocessing,
     for more details, please visit the paper at : arxiv.org]
    Arguments:
        folder {[string]} -- [The Root folder to look into]
        dest_folder {[type]} -- [The folder to store preprocessed files into]
        test {[type]} -- [If doing it for the testing, we don't want to check
                          for ground truths]
    """
    patient_dest_folder = os.path.join(dest_folder, patient_name)
    os.makedirs(patient_dest_folder, exist_ok=True)
    t1 = glob.glob(os.path.join(folder, '*t1.nii.gz'))[0]
    t2 = glob.glob(os.path.join(folder, '*t2.nii.gz'))[0]
    t1ce = glob.glob(os.path.join(folder, '*t1ce.nii.gz'))[0]
    flair = glob.glob(os.path.join(folder, '*flair.nii.gz'))[0]
    if not test:
        gt = glob.glob(os.path.join(folder, '*mask.nii.gz'))[0]

    # Reading T1 image and storing it
    t1_image = nib.load(t1)
    resized_t1_image = preprocess_image(t1_image, is_mask=False)
    temp_affine = t1_image.affine
    resized_t1_image = nib.Nifti1Image(resized_t1_image, temp_affine)
    print(patient_dest_folder)
    print("Saving T1 at : ", os.path.join(patient_dest_folder, patient_name +
                                            "_t1.nii.gz"))
    nib.save(resized_t1_image, os.path.join(patient_dest_folder, patient_name +
                                            "_t1.nii.gz"))

    t2_image = nib.load(t2)
    resized_t2_image = preprocess_image(t2_image, is_mask=False)
    temp_affine = t2_image.affine
    resized_t2_image = nib.Nifti1Image(resized_t2_image, temp_affine)
    nib.save(resized_t2_image, os.path.join(patient_dest_folder, patient_name +
                                            "_t2.nii.gz"))

    t1ce_image = nib.load(t1ce)
    resized_t1ce_image = preprocess_image(t1ce_image, is_mask=False)
    temp_affine = t1ce_image.affine
    resized_t1ce_image = nib.Nifti1Image(resized_t1ce_image,
                                         t1ce_image.affine)
    nib.save(resized_t1ce_image, os.path.join(patient_dest_folder, patient_name +
                                              "_t1ce.nii.gz"))

    flair_image = nib.load(flair)
    resized_flair_image = preprocess_image(flair_image, is_mask=False)
    temp_affine = flair_image.affine
    resized_flair_image = nib.Nifti1Image(resized_flair_image,
                                          flair_image.affine)
    nib.save(resized_flair_image, os.path.join(patient_dest_folder, patient_name
                                               +
                                               "_flair.nii.gz"))

    if not test:
        gt_image = nib.load(gt)
        resized_gt_image = preprocess_image(gt_image, is_mask=True)
        resized_gt_image = nib.Nifti1Image(resized_gt_image,
                                           gt_image.affine)
        nib.save(resized_gt_image, os.path.join(patient_dest_folder, patient_name
                                                +"_mask.nii.gz"))
    return


def batch_works(k):
    if k == n_processes - 1:
        sub_patients = patients[k * int(len(patients) / n_processes):]
    else:
        sub_patients = patients[k * int(len(patients) / n_processes):
                                (k + 1) * int(len(patients) / n_processes)]
    for patient in sub_patients:
        patient_name = os.path.basename(patient)
        print(patient_name)
        normalize(patient, output_path, patient_name)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(prog='intensity_standardize', formatter_class=argparse.RawTextHelpFormatter,
                                     description='\nThis code was implemented to standardize intensities for skull stripping\n'+ '\n'\
    'Copyright: Center for Biomedical Image Computing and Analytics (CBICA), University of Pennsylvania.\n'\
    'For questions and feedback contact: software@cbica.upenn.edu')

    parser.add_argument('-i', '--input_path', dest='input_path',
                        help="input path for the tissues", required=True)
    parser.add_argument('-o', '--output_path', dest='output_path',
                        help="output path for saving the files", required=True)
    parser.add_argument('-t', '--threads', dest='threads',
                        help="number of threads, by default will use all")
                        
    parser.add_argument('-v', '--version', action='version',
                        version=pkg_resources.require("BrainMaGe")[0].version + '\n\nCopyright: Center for Biomedical Image Computing and Analytics (CBICA), University of Pennsylvania.', help="Show program's version number and exit.")
                
    args = parser.parse_args()

    if args.threads:
        n_processes = int(args.threads)
    else:
        n_processes = cpu_count()
    print("Number of CPU's used : ", n_processes)

    input_path = os.path.abspath(args.input_path)
    output_path = os.path.abspath(args.output_path)
    os.makedirs(output_path, exist_ok=True)
    patients = glob.glob(os.path.abspath(args.input_path)+'/*')
    n_processes = cpu_count()
    pool = Pool(processes=n_processes)
    pool.map(batch_works, range(n_processes))
